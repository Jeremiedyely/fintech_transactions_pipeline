{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c333bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credit_card_number', 'first_name', 'last_name', 'gender', 'date_of_birth', 'job', 'street_address', 'city', 'state', 'zip_code', 'latitude', 'longitude', 'city_population', 'merchant_name', 'merchant_category', 'merchant_latitude', 'merchant_longitude', 'transaction_id', 'transaction_amount', 'transaction_date', 'transaction_time', 'unix_timestamp', 'is_fraud', 'unix_datetime', 'seconds_since_last_txn']\n",
      "Cleaned data saved to: ../data/processed/fraudTrain_cleaned.csv\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\data\\processed\\outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 305\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCleaned data saved to: ../data/processed/fraudTrain_cleaned.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    304\u001b[39m \u001b[38;5;66;03m# Save summary outputs if needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/processed/outputs/clean_summary.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSummary saved to: ../data/processed/outputs/clean_summary.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    308\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.columns.tolist())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\fintech_transactions_pipeline\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\fintech_transactions_pipeline\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\fintech_transactions_pipeline\\venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\fintech_transactions_pipeline\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\fintech_transactions_pipeline\\venv\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\fintech_transactions_pipeline\\venv\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '..\\data\\processed\\outputs'"
     ]
    }
   ],
   "source": [
    "#Extract raw data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/fraudTrain.csv\")\n",
    "\n",
    "# Clean data — fix column names and split date and time.\n",
    "\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.lower()\n",
    "df[\"trans_date_trans_time\"] = pd.to_datetime(df[\"trans_date_trans_time\"])\n",
    "df[\"transaction_date\"] = df[\"trans_date_trans_time\"].dt.date\n",
    "df[\"transaction_time\"] = df[\"trans_date_trans_time\"].dt.time\n",
    "df = df.drop(columns=[\"trans_date_trans_time\"])\n",
    "\n",
    "# Rename columns for clarity and readability\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"cc_num\": \"credit_card_number\",\n",
    "        \"merchant\": \"merchant_name\",\n",
    "        \"category\": \"merchant_category\",\n",
    "        \"amt\": \"transaction_amount\",\n",
    "        \"first\": \"first_name\",\n",
    "        \"last\": \"last_name\",\n",
    "        \"street\": \"street_address\",\n",
    "        \"zip\": \"zip_code\",\n",
    "        \"lat\": \"latitude\",\n",
    "        \"long\": \"longitude\",\n",
    "        \"city_pop\": \"city_population\",\n",
    "        \"dob\": \"date_of_birth\",\n",
    "        \"trans_num\": \"transaction_id\",\n",
    "        \"unix_time\": \"unix_timestamp\",\n",
    "        \"merch_lat\": \"merchant_latitude\",\n",
    "        \"merch_long\": \"merchant_longitude\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# Reorder columns for better organization\n",
    "column_order = [\n",
    "    \"credit_card_number\",\n",
    "    \"first_name\",\n",
    "    \"last_name\",\n",
    "    \"gender\",\n",
    "    \"date_of_birth\",\n",
    "    \"job\",\n",
    "    \"street_address\",\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"zip_code\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"city_population\",\n",
    "    \"merchant_name\",\n",
    "    \"merchant_category\",\n",
    "    \"merchant_latitude\",\n",
    "    \"merchant_longitude\",\n",
    "    \"transaction_id\",\n",
    "    \"transaction_amount\",\n",
    "    \"transaction_date\",\n",
    "    \"transaction_time\",\n",
    "    \"unix_timestamp\",\n",
    "    \"is_fraud\",\n",
    "]\n",
    "\n",
    "df = df[column_order]\n",
    "\n",
    "# Clean + mask card numbers (preserve zeros; privacy-safe)\n",
    "df[\"credit_card_number\"] = df[\"credit_card_number\"].astype(str)\n",
    "df[\"credit_card_number\"] = df[\"credit_card_number\"].str.replace(\n",
    "    r\"\\D\", \"\", regex=True\n",
    ")\n",
    "df[\"valid_length\"] = df[\"credit_card_number\"].str.len().between(13, 16)\n",
    "df[\"masked_card\"] = df[\"credit_card_number\"].apply(\n",
    "    lambda s: \"*\" * max(len(s) - 4, 0) + s[-4:]\n",
    ")\n",
    "df[\"credit_card_number\"] = df[\"masked_card\"]\n",
    "df = df.drop(columns=[\"masked_card\"])\n",
    "\n",
    "# Short summary (no full numbers printed)\n",
    "valid_count = df[\"valid_length\"].sum()\n",
    "invalid_count = (~df[\"valid_length\"]).sum()\n",
    "total = len(df)\n",
    "\n",
    "# Drop invalid credit card numbers — keep a copy of the old dataframe. Keep only valid cards\n",
    "df_old = df.copy()\n",
    "df = df[df[\"valid_length\"]]\n",
    "df = df.drop(columns=[\"valid_length\"]) \n",
    "\n",
    "# Clean merchant column - Remove 'fraud_' prefix, and trim spaces\n",
    "\n",
    "df[\"merchant_name\"] = (\n",
    "    df[\"merchant_name\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"^fraud_\", \"\", regex=True)\n",
    "    .str.replace(r\"[^\\w\\s,&-]\", \"\", regex=True)\n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "#make merchant_category values more readable  #PEP8 STOP HERE\n",
    "df[\"merchant_category\"] = (\n",
    "    df[\"merchant_category\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"^fraud_\", \"\", regex=True)\n",
    "    .str.replace(r\"[^\\w\\s&-]\", \"\", regex=True)\n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "# Clean first_name and last_name columns\n",
    "df[\"first_name\"] = (\n",
    "    df[\"first_name\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"[^\\w\\s'-]\", \"\", regex=True)  \n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)    \n",
    "    .str.strip()                                \n",
    "    .str.title()                                \n",
    ")\n",
    "\n",
    "df[\"last_name\"] = (\n",
    "    df[\"last_name\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"[^\\w\\s'-]\", \"\", regex=True)\n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)\n",
    "    .str.strip()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "# Clean and normalize job titles\n",
    "df[\"job\"] = (\n",
    "    df[\"job\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"[^\\w\\s/&-]\", \"\", regex=True)   \n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)      \n",
    "    .str.strip()                                  \n",
    "    .str.title()                                  \n",
    ")\n",
    "\n",
    "# Clean street_address column\n",
    "df[\"street_address\"] = (\n",
    "    df[\"street_address\"]\n",
    "    .astype(str)                                 \n",
    "    .str.replace(r\"[^\\w\\s\\.-]\", \"\", regex=True)  \n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)     \n",
    "    .str.strip()                                 \n",
    "    .str.title()                                \n",
    ")\n",
    "\n",
    "# Clean city column — remove invalid characters, fix spacing, and standardize casing.\n",
    "df[\"city\"] = (\n",
    "    df[\"city\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"[^\\w\\s'-]\", \"\", regex=True)      \n",
    "    .str.replace(r\"\\s{2,}\", \" \", regex=True)        \n",
    "    .str.strip()\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "# Replace missing or empty city values with a consistent label.\n",
    "df[\"city\"] = df[\"city\"].replace(\"\", pd.NA).fillna(\"Unknown City\")\n",
    "\n",
    "df[\"state\"] = (\n",
    "    df[\"state\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    ")\n",
    "\n",
    "df[\"zip_code\"] = (\n",
    "    df[\"zip_code\"]\n",
    "    .astype(str)                                \n",
    "    .str.replace(r\"\\D\", \"\", regex=True)         \n",
    "    .str.zfill(5)                               \n",
    ")\n",
    "df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "df.loc[(df[\"latitude\"] < -90) | (df[\"latitude\"] > 90), \"latitude\"] = pd.NA\n",
    "df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")\n",
    "df.loc[(df[\"longitude\"] < -180) | (df[\"longitude\"] > 180), \"longitude\"] = pd.NA \n",
    "\n",
    "df[\"city_population\"] = pd.to_numeric(df[\"city_population\"], errors=\"coerce\")\n",
    "df[\"city_population\"] = df[\"city_population\"].astype(\"Int64\")\n",
    "\n",
    "df.loc[\n",
    "    (df[\"city_population\"] < 50) |               \n",
    "    (df[\"city_population\"] > 15_000_000),        \n",
    "    \"city_population\"\n",
    "] = pd.NA\n",
    "\n",
    "df.loc[df[\"city\"] == \"Unknown City\", \"city_population\"] = pd.NA\n",
    "\n",
    "# Clean merchant_latitude column Convert to numeric and remove invalid geolocation values.\n",
    "\n",
    "df[\"merchant_latitude\"] = pd.to_numeric(df[\"merchant_latitude\"], errors=\"coerce\")\n",
    "\n",
    "df.loc[\n",
    "    (df[\"merchant_latitude\"] < -90) |\n",
    "    (df[\"merchant_latitude\"] > 90),\n",
    "    \"merchant_latitude\"\n",
    "] = pd.NA\n",
    "\n",
    "# Clean merchant_longitude column Convert to numeric and enforce valid longitude range.\n",
    "df[\"merchant_longitude\"] = pd.to_numeric(df[\"merchant_longitude\"], errors=\"coerce\")\n",
    "\n",
    "df.loc[\n",
    "    (df[\"merchant_longitude\"] < -180) |\n",
    "    (df[\"merchant_longitude\"] > 180),\n",
    "    \"merchant_longitude\"\n",
    "] = pd.NA\n",
    "\n",
    "# Clean transaction_id column Normalize text, remove invalid characters, ensure consistent key formatting.\n",
    "df[\"transaction_id\"] = (\n",
    "    df[\"transaction_id\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(r\"[^\\w-]\", \"\", regex=True) \n",
    ")\n",
    "\n",
    "df[\"transaction_id\"] = df[\"transaction_id\"].replace(\"\", pd.NA)\n",
    "df[\"transaction_id\"] = df[\"transaction_id\"].astype(\"string\") #\n",
    "\n",
    "# Clean transaction_amount column Convert to numeric, remove invalid values, and create BI-friendly buckets.\n",
    "df[\"transaction_amount\"] = pd.to_numeric(df[\"transaction_amount\"], errors=\"coerce\")\n",
    "df.loc[\n",
    "    (df[\"transaction_amount\"] <= 0) |\n",
    "    (df[\"transaction_amount\"] > 50_000),\n",
    "    \"transaction_amount\"\n",
    "] = pd.NA\n",
    "\n",
    "# Clean transaction_date column Convert to datetime format for BI time-series analysis.\n",
    "df[\"transaction_date\"] = pd.to_datetime(\n",
    "    df[\"transaction_date\"],\n",
    "    format=\"%m/%d/%Y\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Clean transaction_time column Convert to Python time format and extract hour for BI analysis.\n",
    "df[\"transaction_time\"] = pd.to_datetime(\n",
    "    df[\"transaction_time\"],\n",
    "    format=\"%H:%M:%S\",\n",
    "    errors=\"coerce\"\n",
    ").dt.time\n",
    "\n",
    "# Clean unix_timestamp column Convert to numeric and validate range.\n",
    "df[\"unix_timestamp\"] = pd.to_numeric(df[\"unix_timestamp\"], errors=\"coerce\")\n",
    "\n",
    "df.loc[\n",
    "    (df[\"unix_timestamp\"] < 946684800) |    # Jan 1, 2000\n",
    "    (df[\"unix_timestamp\"] > 1735689600),   # Jan 1, 2025\n",
    "    \"unix_timestamp\",\n",
    "] = pd.NA\n",
    "\n",
    "# Convert unix_timestamp to precise datetime.Create human-readable unix_datetime from raw UNIX seconds.\n",
    "df[\"unix_datetime\"] = pd.to_datetime(\n",
    "    df[\"unix_timestamp\"],\n",
    "    unit=\"s\",\n",
    "    errors=\"coerce\",\n",
    ")\n",
    "\n",
    "# Sort rows by card and time before computing differences.Order transactions per card chronologically.\n",
    "df = df.sort_values([\"credit_card_number\", \"unix_datetime\"])\n",
    "\n",
    "# Calculate seconds since last transaction (per card).Compute time gaps between consecutive swipes for each card.\n",
    "df[\"seconds_since_last_txn\"] = (\n",
    "    df.groupby(\"credit_card_number\")[\"unix_datetime\"]\n",
    "    .diff()\n",
    "    .dt.total_seconds()\n",
    ")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Clean gender column. Action: Standardize values to M, F, or Unknown.\n",
    "\n",
    "df[\"gender\"] = (\n",
    "    df[\"gender\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "# Map common variants to standard categories\n",
    "gender_map = {\n",
    "    \"m\": \"M\",\n",
    "    \"male\": \"M\",\n",
    "    \"f\": \"F\",\n",
    "    \"female\": \"F\",\n",
    "}\n",
    "\n",
    "df[\"gender\"] = df[\"gender\"].map(gender_map).fillna(\"Unknown\")\n",
    "\n",
    "# Clean is_fraud column. Convert to numeric 0/1 and enforce binary values.\n",
    "df[\"is_fraud\"] = pd.to_numeric(df[\"is_fraud\"], errors=\"coerce\")\n",
    "df.loc[~df[\"is_fraud\"].isin([0, 1]), \"is_fraud\"] = pd.NA\n",
    "df[\"is_fraud\"] = df[\"is_fraud\"].astype(\"Int64\")\n",
    "\n",
    "df[\"city_population_missing\"] = df[\"city_population\"].isna()\n",
    "df[\"transaction_amount_missing\"] = df[\"transaction_amount\"].isna()\n",
    "df[\"latlong_missing\"] = df[\"latitude\"].isna() | df[\"longitude\"].isna()\n",
    "df[\"seconds_since_last_txn_missing\"] = df[\"seconds_since_last_txn\"].isna()\n",
    "\n",
    "# LOAD STEP (save cleaned data)\n",
    "df.to_csv(\"../data/processed/fraudTrain_cleaned.csv\", index=False)\n",
    "print(\"Cleaned data saved to: ../data/processed/fraudTrain_cleaned.csv\")\n",
    "\n",
    "# Save summary outputs if needed\n",
    "df.describe(include=\"all\").to_csv(\"../data/processed/outputs/clean_summary.csv\")\n",
    "print(\"Summary saved to: ../data/processed/outputs/clean_summary.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
